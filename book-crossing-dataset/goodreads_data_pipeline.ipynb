{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['isbn', 'text_reviews_count', 'series', 'country_code', 'language_code',\n",
       "       'popular_shelves', 'asin', 'is_ebook', 'average_rating', 'kindle_asin',\n",
       "       'similar_books', 'description', 'format', 'link', 'authors',\n",
       "       'publisher', 'num_pages', 'publication_day', 'isbn13',\n",
       "       'publication_month', 'edition_information', 'publication_year', 'url',\n",
       "       'image_url', 'book_id', 'ratings_count', 'work_id', 'title',\n",
       "       'title_without_series'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goodreads = pd.read_json('data/goodreads_books_comics_graphic.json', lines=True)\n",
    "\n",
    "goodreads.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For interactions, we will need use the key below to convert the book_id to the work_id\n",
    "work_id_book_id_dict = goodreads.groupby('work_id').agg({'book_id': list}) # Look for book_id here, and use the work_id to convert\n",
    "work_id_book_id_dict.to_csv('work_id_book_id_dict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodreads['author_ids'] = goodreads['authors'].apply(lambda x: ' '.join([author['author_id'] for author in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = ['work_id', 'title', 'author_ids', 'description', 'publication_year', 'ratings_count', 'average_rating', 'num_pages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataframe: (89411, 30)\n",
      "Aggregated dataframe: (62944, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Group by work_id and keep only the specified columns\n",
    "\n",
    "# First, sort the dataframe by work_id and ratings_count (descending)\n",
    "sorted_df = goodreads.sort_values(['work_id', 'ratings_count'], ascending=[True, False])\n",
    "\n",
    "# Define a function to get the best values from a group of books with the same work_id\n",
    "def get_best_row(group):\n",
    "    # Start with the row with the highest ratings_count\n",
    "    best_row = group.iloc[0].copy()\n",
    "    \n",
    "    # For each column we want to potentially fill from other books\n",
    "    for col in ['description', 'publication_year', 'num_pages']:\n",
    "        # If the value is empty\n",
    "        if pd.isna(best_row[col]) or best_row[col] == '':\n",
    "            # Look for a non-empty value in the group\n",
    "            non_empty = group[(~group[col].isna()) & (group[col] != '')]\n",
    "            if len(non_empty) > 0:\n",
    "                best_row[col] = non_empty.iloc[0][col]\n",
    "    \n",
    "    return best_row\n",
    "\n",
    "# Apply the function to each group of books with the same work_id\n",
    "best_rows = []\n",
    "for _, group in sorted_df.groupby('work_id'):\n",
    "    best_rows.append(get_best_row(group))\n",
    "\n",
    "# Create a dataframe from the best rows\n",
    "max_ratings_data = pd.DataFrame(best_rows)[cols_from_max_rating]\n",
    "\n",
    "# Calculate the aggregated statistics\n",
    "agg_stats = goodreads.groupby('work_id').agg({\n",
    "    'ratings_count': 'sum',\n",
    "    'average_rating': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Combine the data\n",
    "goodreads_works = max_ratings_data.merge(agg_stats, on='work_id')\n",
    "\n",
    "# Ensure the columns are in the right order\n",
    "goodreads_works = goodreads_works[cols_to_keep]\n",
    "\n",
    "# Display the shape of the resulting dataframe\n",
    "print(f\"Original dataframe: {goodreads.shape}\")\n",
    "print(f\"Aggregated dataframe: {goodreads_works.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_criterion = goodreads_works[goodreads_works['description'].apply(lambda x: len(x) != 0)]['work_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering for english books (mainly)\n",
    "\n",
    "#goodreads_children['language_code'].apply(lambda x: \"\" if re.match()) # Change any number of spaces to just empty string\n",
    "language_criterion = goodreads[goodreads['language_code'].apply(lambda x: x in [\"\", 'eng', 'en-US', 'en-GB', 'en-CA'])]['work_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = goodreads_works[goodreads_works['work_id'].isin(description_criterion) & goodreads_works['work_id'].isin(language_criterion)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('data/goodreads_books_comics_graphic_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
