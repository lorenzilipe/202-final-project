{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qdrant Creation Functions\n",
    "- create_book_embeddingings\n",
    "-- creates vector embeddings from a books data frame\n",
    "- upload_to_qdrant\n",
    "-- takes book vectors and uploads them to qdrant\n",
    "- process_book_data frame\n",
    "-- run the book data frame through this to put it all together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_book_embeddings(df, column_name=\"summary\", model_name=\"all-MiniLM-L6-v2\"):\n",
    "    \"\"\"\n",
    "    Generate embeddings for a dataframe of books.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas DataFrame containing the book data\n",
    "    - column_name: the column to generate embeddings for (defaults to \"summary\")\n",
    "    - model_name: the sentence transformer model to use\n",
    "    \n",
    "    Returns:\n",
    "    - list of point objects ready for Qdrant upload\n",
    "    \"\"\"\n",
    "    # Load embedding model\n",
    "    model = SentenceTransformer(model_name)\n",
    "    \n",
    "    # Get the model's output dimension\n",
    "    vector_size = model.get_sentence_embedding_dimension()\n",
    "    \n",
    "    # Convert descriptions to embeddings\n",
    "    book_vectors = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        vector = model.encode(row[column_name]).tolist()\n",
    "        book_vectors.append({\n",
    "            \"id\": index + 1,  # Assign unique ID\n",
    "            \"vector\": vector,\n",
    "            \"payload\": {\"title\": row.get(\"title\", \"\"), \"summary\": row.get(column_name, \"\")}\n",
    "        })\n",
    "    \n",
    "    return book_vectors, vector_size\n",
    "\n",
    "def upload_to_qdrant(book_vectors, vector_size, client=None, url=None, api_key=None, \n",
    "                     collection_name=\"books\", batch_size=100):\n",
    "    \"\"\"\n",
    "    Upload book embeddings to Qdrant.\n",
    "    \n",
    "    Parameters:\n",
    "    - book_vectors: list of vector points to upload\n",
    "    - vector_size: dimensionality of the embedding vectors\n",
    "    - client: an existing QdrantClient (optional)\n",
    "    - url: Qdrant server URL (required if client not provided)\n",
    "    - api_key: Qdrant API key (required if client not provided)\n",
    "    - collection_name: name for the Qdrant collection\n",
    "    - batch_size: number of vectors to upload in each batch\n",
    "    \n",
    "    Returns:\n",
    "    - QdrantClient instance\n",
    "    \"\"\"\n",
    "    # Create client if not provided\n",
    "    if client is None:\n",
    "        if url is None or api_key is None:\n",
    "            raise ValueError(\"Either provide a client or both url and api_key\")\n",
    "        client = QdrantClient(url, api_key=api_key)\n",
    "    \n",
    "    # Create/recreate collection with appropriate vector size\n",
    "    client.recreate_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=VectorParams(size=vector_size, distance=Distance.COSINE)\n",
    "    )\n",
    "    \n",
    "    # Upload vectors in batches\n",
    "    for i in range(0, len(book_vectors), batch_size):\n",
    "        batch = book_vectors[i : i + batch_size]\n",
    "        client.upsert(collection_name=collection_name, points=batch)\n",
    "        print(f\"Uploaded batch {i // batch_size + 1} of {(len(book_vectors) - 1) // batch_size + 1}\")\n",
    "    \n",
    "    print(\"Upload complete!\")\n",
    "    return client\n",
    "\n",
    "def process_book_dataframe(df, column_name=\"summary\", model_name=\"all-MiniLM-L6-v2\", \n",
    "                          url=None, api_key=None, collection_name=\"books\", batch_size=100):\n",
    "    \"\"\"\n",
    "    End-to-end function to process a book dataframe and upload to Qdrant.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas DataFrame containing the book data\n",
    "    - column_name: the column to generate embeddings for\n",
    "    - model_name: the sentence transformer model to use\n",
    "    - url: Qdrant server URL\n",
    "    - api_key: Qdrant API key\n",
    "    - collection_name: name for the Qdrant collection\n",
    "    - batch_size: number of vectors to upload in each batch\n",
    "    \n",
    "    Returns:\n",
    "    - QdrantClient instance\n",
    "    \"\"\"\n",
    "    # Generate embeddings\n",
    "    book_vectors, vector_size = create_book_embeddings(df, column_name, model_name)\n",
    "    \n",
    "    # Upload to Qdrant\n",
    "    client = upload_to_qdrant(\n",
    "        book_vectors, \n",
    "        vector_size,\n",
    "        url=url, \n",
    "        api_key=api_key, \n",
    "        collection_name=collection_name,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
